{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "# Topic extraction with Non-negative Matrix Factorization and Latent Dirichlet Allocation\n",
    "\n",
    "\n",
    "This is an example of applying Non-negative Matrix Factorization\n",
    "and Latent Dirichlet Allocation on a corpus of documents and\n",
    "extract additive models of the topic structure of the corpus.\n",
    "The output is a list of topics, each represented as a list of terms\n",
    "(weights are not shown).\n",
    "\n",
    "The default parameters (n_samples / n_features / n_topics) should make\n",
    "the example runnable in a couple of tens of seconds. You can try to\n",
    "increase the dimensions of the problem, but be aware that the time\n",
    "complexity is polynomial in NMF. In LDA, the time complexity is\n",
    "proportional to (n_samples * iterations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 10000\n",
    "n_features = 1000\n",
    "n_topics = 19\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "10723\n",
      "['alt.atheism', 'comp.graphics', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "10723\n",
      "done in 2.300s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nThere was a recession, and none of the potential entrants could raise any\\nmoney.  The race organizers were actually supposed to be handling part of\\nthe fundraising, but the less said about that the better.',\n",
       " \"\\nI only have one comment on this:  You call this a *classic* playoff year\\nand yet you don't include a Chicago-Detroit series.  C'mon, I'm a Boston\\nfan and I even realize that Chicago-Detroit games are THE most exciting\\ngames to watch.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "categories = ['alt.atheism', 'comp.graphics',\n",
    "              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "              'comp.windows.x', 'misc.forsale', 'rec.autos',\n",
    "              'rec.motorcycles', 'rec.sport.baseball',\n",
    "              'rec.sport.hockey', 'sci.crypt', 'sci.electronics',\n",
    "              'sci.med', 'sci.space', 'soc.religion.christian',\n",
    "              'talk.politics.guns', 'talk.politics.mideast',\n",
    "              'talk.politics.misc', 'talk.religion.misc']\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,categories=categories,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "print(len(dataset.filenames))\n",
    "print(dataset.target_names)\n",
    "print(len(dataset.data))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "len(data_samples)\n",
    "data_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 2.169s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 1.820s.\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model with tf-idf features, n_samples=10000 and n_features=1000...\n",
      "done in 1.857s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "people time right did good say make said way government really point going years want things believe course long didn\n",
      "Topic #1:\n",
      "thanks advance mail hi looking info address email information appreciated post help anybody send interested list reply tell need good\n",
      "Topic #2:\n",
      "god jesus bible christ faith believe christian christians sin church lord hell life truth man belief love christianity say son\n",
      "Topic #3:\n",
      "game team year games season players play hockey win league player teams nhl baseball good runs toronto best hit better\n",
      "Topic #4:\n",
      "new 00 sale price 10 offer shipping condition 20 50 interested asking 15 12 email 11 sell 25 30 excellent\n",
      "Topic #5:\n",
      "drive scsi disk drives hard ide controller floppy cd bus internal cable mac tape rom mb power apple ram card\n",
      "Topic #6:\n",
      "key chip encryption clipper keys escrow government public algorithm nsa security phone secure chips bit des secret number use law\n",
      "Topic #7:\n",
      "edu soon cs university email com article internet send david mail mit pub reply apr subject 1993 ftp mac export\n",
      "Topic #8:\n",
      "don want mean oh tell care try understand read little look believe say sorry things hope case ask ll pretty\n",
      "Topic #9:\n",
      "car cars engine speed miles good oil driver drivers looks power price road bought insurance buy radio fast door gas\n",
      "Topic #10:\n",
      "just ll thought wanted maybe little oh bit work tell mean sure guess fine bad doesn got wait bike base\n",
      "Topic #11:\n",
      "does mean anybody say exist help board work chips getting exactly doesn actually new make clear message read answer claim\n",
      "Topic #12:\n",
      "use card window using program windows problem file software graphics need video monitor work pc color files screen help memory\n",
      "Topic #13:\n",
      "like sounds looks look bike lot sound thing doing things hear doesn new try nice sell really going looked sure\n",
      "Topic #14:\n",
      "space nasa shuttle launch orbit station moon earth gov sci program satellite research cost data center science commercial technology idea\n",
      "Topic #15:\n",
      "know let need anybody doesn maybe sure didn getting appreciated interested source help kind heard far wanted really going happen\n",
      "Topic #16:\n",
      "ve got seen heard tried recently months try times maybe help years problems good thing ll best couple past great\n",
      "Topic #17:\n",
      "israel israeli jews arab jewish peace war land state anti killed policy rights citizens human american center solution fact states\n",
      "Topic #18:\n",
      "think try lot pretty makes bit really original wasn agree thinking better extra steve come remember science moral worth way\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=10000 and n_features=1000...\n",
      "done in 26.790s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "db cs al gas west east bits edu lower higher add bit place stuff left south right data north 10\n",
      "Topic #1:\n",
      "god jesus does believe christian people bible say think faith true church religion christ christians evidence argument life way word\n",
      "Topic #2:\n",
      "don just like time ve think know good way going people want make say really car work right years things\n",
      "Topic #3:\n",
      "10 25 12 15 11 16 20 17 50 13 18 14 30 24 21 40 55 19 22 23\n",
      "Topic #4:\n",
      "game year team games play season players win hockey league points teams player nhl baseball best good goal played think\n",
      "Topic #5:\n",
      "file ftp program image files edu available server version pub output code anonymous graphics archive use entry format info images\n",
      "Topic #6:\n",
      "jews israel war jewish israeli anti oil land arab peace state south military policy picture countries citizens human center attack\n",
      "Topic #7:\n",
      "gun government mr law people state right rights guns control weapons laws federal firearms tax police states president congress stephanopoulos\n",
      "Topic #8:\n",
      "00 space nasa 000 center launch new engine cost shuttle gov earth 01 orbit moon dc 02 station research cover\n",
      "Topic #9:\n",
      "drive disk problem hard dos use drives power using ms floppy pin ground windows cable tape supply wire installed used\n",
      "Topic #10:\n",
      "information window data use available application motif based systems request internet using widget user users software manager computer applications include\n",
      "Topic #11:\n",
      "know just post don question read didn posting like said did time day article news got think asked ll questions\n",
      "Topic #12:\n",
      "dod good like know don just bike think does mean look oh thing nice lot right ll numbers great looking\n",
      "Topic #13:\n",
      "edu com thanks mail send email new computer price monitor list does sale info help advance like interested offer shipping\n",
      "Topic #14:\n",
      "people did children death dead live life group face country kill wrong killed matter black come society men white think\n",
      "Topic #15:\n",
      "key encryption chip clipper keys government use security public privacy des enforcement technology law algorithm secure escrow used nsa bit\n",
      "Topic #16:\n",
      "new university president american years health states united national book year world medical general press april program research 1993 state\n",
      "Topic #17:\n",
      "scsi bit card speed memory mac pc bus controller data mode 16 video use os 32 board drivers ibm ide\n",
      "Topic #18:\n",
      "armenian turkish armenians said people turkey greek women turks armenia genocide killed soviet russian city government army came children population\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThere was a recession, and none of the potential entrants could raise any\\nmoney.  The race organizers were actually supposed to be handling part of\\nthe fundraising, but the less said about that the better.',\n",
       " \"\\nI only have one comment on this:  You call this a *classic* playoff year\\nand yet you don't include a Chicago-Detroit series.  C'mon, I'm a Boston\\nfan and I even realize that Chicago-Detroit games are THE most exciting\\ngames to watch.\",\n",
       " '\\n\\nI\\'m not quite sure how these numbers are generated.  It appears that in\\na neutral park Bo\\'s HR and slugging tend to drop (he actually loses two\\nhome runs).  Or do they?  What is \"equivalent average?\"\\n\\nOne thing, when looking at Bo\\'s stats, is that you can see that KC took\\naway some homers.  Normally, you expect some would-be homers to go for\\ndoubles or triples in big parks, or to be caught, and for that matter you\\nexpect lots of doubles and triples anyway.  But Bo, despite his speed, \\nhit very few doubles and not that many triples.  So I would expect his\\nvalue to have risen quite considerably in a neutral park.  \\n\\n\\nFelix Jose has been a .350/.440 player in a fairly neutral park.\\nI would offhand guess the `89-`90 Bo at around a .330/.530 player.\\nMaybe .330/.550 .  Not even close.\\n\\n\\nI\\'d put him about there too.  \\n\\nNote: I hadn\\'t realized the media had hyped him so much.  I thought he\\nwas always viewed by them as a better football player, and only so-so \\nat baseball.  He did only have one 30-hr, 100-rbi season, and KC wasn\\'t\\nwinning.\\n\\nNote 2: I maybe have harped on this a bit in the past, but there is a\\nmistake being made (by the SDCN\\'s, as they are known, on this group)\\nwith respect to players like Bo and Deion and Lofton (and perhaps others).\\n\\nWe find, that if you look at a large group of players, their past major\\nand minor league numbers will predict their future numbers fairly well.\\nTheir are some caveats: the younger they are, the less good the prediction;\\nthe lower the minor league, the less good (I imagine), the more recent\\nthe player has left college ball, etc.\\n\\nNow of course, this prediction involves quite a bit of \"error.\"  Sometimes\\na player with poor MLE\\'s (Dave Justice, the 1990 Ventura) becomes a star.\\nSome hitters develop (Shane Mack, Brian Downing), some don\\'t (Oddibe\\nMcDowell, Mickey Brantley).  This error involves real things: there are\\nreal reasons why Oddibe didn\\'t hit and Shane did.  It may (who knows)\\ninvolve parks and batting coaches and wheaties and injuries and lifting\\nand so on.\\n\\nBut still, you have this big pool of players, and things work pretty well.\\nOne of the reasons for these predictions accuracy is the common background\\nof the players.  One thing we know about professional baseball players is\\nthat all of them (or almost all) have spent a good deal of time playing\\nball.  Their backgrounds are similar.\\n\\nWhat hasn\\'t been established is what happens when you encounter a player\\nwith a different background?  Is there some reason to believe that a\\nBo, or a Deion, or a Lofton, or a Tony Gwynn (?), or an Ainge, or so\\non, has such a different background, that the standard model and standard\\nassumptions fit this person slowly?\\n\\nIt hasn\\'t been established that you can use MLE\\'s with two-sport players.\\n(It hasn\\'t been established that you can\\'t, but then statistics is, after\\nall, an art).  I personally think otherwise lucid individuals continually\\nmake completely nonsensical statements about Bo and Deion and Lofton.\\n\"Look at those good-but-not-great minor league numbers,\" they say.  Well,\\nwhat happens if those numbers simply don\\'t mean what they usually mean?\\nIt might mean that Ken Lofton suddenly has a better year in Houston than\\nTuscon.  It might mean that Deion suddenly has a better half-year in\\nAtlanta than Greenville.  \\n\\nThen again, it might not.  Ken and Deion might go right back in the tank\\nthis year, live up to those poor MLE\\'s.  But you guys DON\\'T KNOW.  What\\'s \\nworse, you don\\'t know that you don\\'t.  And you don\\'t know that there are \\nother players you won\\'t know about -- injuries and lifting and wheaties \\nagain.  You seem to think that the model is perfect and eternal.  It\\'s not.\\nIt\\'s got some error.\\n\\nOh well.\\n\\nBill Guilford',\n",
       " \"\\nFor better worse, the source on this on is Michael Barnsley. His article\\nin The Science of Fractal Images (Peitgen et al) is a fair-to-middling\\nintro. Barnsley's book Fractals Everywhere is a more thorough treatment.\\nThe book covers Iterated Function Systems in general, and their application\\nto image compression is clear from the text.\",\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
